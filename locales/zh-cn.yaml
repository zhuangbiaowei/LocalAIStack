"- %s\t%s": "- %s\t%s"
CPU threads for llama.cpp (0 = auto): '`lama.cpp` 的 CPU 线程数（0 表示自动分配）：'
Check module installation status: 检查模块的安装状态。
Context size for llama.cpp (0 = auto): '`lama.cpp` 的上下文大小（0 表示自动设置）'
Detect hardware capabilities: 检测硬件功能
Download a model: 下载一个模型。
'Error: %v': 错误：%v
Force removal without confirmation: 强制移除，无需确认
GPU layers for llama.cpp (-1 = auto): '`lama.cpp` 中的 GPU 层（-1 表示自动选择）'
Generate the autocompletion script for bash: 生成 Bash 的自动补全脚本：
Generate the autocompletion script for fish: |-
    由于“fish”是一个非常通用的术语，它可以指代很多不同的东西（比如一种编程语言、一种鱼类、一种工具等），因此很难为其生成一个具体的“自动完成脚本”。如果您能提供更多关于您想要生成的自动完成脚本的具体信息（比如它应该用于哪种编程语言、它应该支持哪些功能等），我会更能够帮助您。

    不过，我可以为您提供一个通用的自动完成脚本的基本框架，您可以根据自己的需求进行修改和扩展。以下是一个使用 Python 语言编写的简单自动完成脚本示例：

    ```python
    def auto_complete(text, suggestions):
        # 将文本分割成单词列表
        words = text.split()

        # 初始化建议列表
        suggestions = []

        # 遍历单词列表
        for word in words:
            # 如果单词在建议列表中，将其添加到建议列表中
            if word in suggestions:
                continue

            # 构建建议字符串
            suggestion = f"{word} {suggestions[-1]}"

            # 将建议字符串添加到建议列表中
            suggestions.append(suggestion)

        # 返回建议列表
        return suggestions

    # 示例使用
    text = "fish"
    suggestions = auto_complete(text)
    print(suggestions)
    ```

    这个脚本定义了一个名为 `auto_complete` 的函数，该函数接受两个参数：`text` 和 `suggestions`。`text` 是用户输入的文本，`suggestions` 是一个包含建议的列表。函数首先将文本分割成单词列表，然后遍历单词列表，对于每个单词，如果该单词不在建议列表中，就构建一个新的建议字符串（在建议字符串的末尾添加建议列表中的最后一个单词），并将这个新的建议字符串添加到建议列表中。最后，函数返回建议列表。

    如果您需要为特定的编程语言或工具生成自动完成脚本，请提供更多详细信息，我会尽力帮助您。
? |
    Generate the autocompletion script for localaistack for the specified shell.
    See each sub-command's help for details on how to use the generated script.
: "为指定的 shell 生成 localizationstack 的自动完成脚本。  \n有关如何使用生成的脚本的详细信息，请参阅每个子命令的帮助文档。"
Generate the autocompletion script for powershell: |-
    以下是一个简单的 PowerShell 自动补全脚本示例：

    ```powershell
    # 创建一个自定义的自动补全函数
    function CustomCompletionFunction($prompt, $ completions) {
        $completedLine = ""
        $currentWord = $prompt[$position]

        # 如果当前单词以空格或句点结尾，则继续匹配后面的单词
        if [$currentWord -eq " " -or [$currentWord -eq "."] {
            $completedLine += $currentWord
            $position += 1
        } else {
            # 遍历提供的补全选项
            foreach ($completion in $completions) {
                $newLine = $currentWord + " " + $completion
                if [$newLine -ne "$completedLine"] {
                    $completedLine = $newLine
                    $position = 0
                    break
                }
            }
        }

        # 如果没有找到匹配的补全选项，则返回原始的提示字符串
        if [$position -eq $prompt.Length] {
            $completedLine = $prompt
        }

        return $completedLine
    }

    # 设置 PowerShell 的自动补全功能
    Set-ScriptCompletionFunction CustomCompletionFunction

    # 测试自动补全功能
    $prompt = "Type the name of a function: "
    $completions = @("Get-Item", "Set-Item", "Test-Item")
    $completedLine = Get-Completions $prompt
    Write-Host "$completedLine"
    ```

    这个脚本定义了一个名为 `CustomCompletionFunction` 的函数，该函数接受两个参数：`$prompt`（提示字符串）和 `$completions`（补全选项列表）。函数会根据提示字符串的内容和提供的补全选项来生成一个完整的命令行。然后，使用 `Set-ScriptCompletionFunction` 命令将这个函数设置为 PowerShell 的自动补全功能。最后，我们测试了这个功能，输入了一个提示字符串并显示了生成的补全选项列表。
? |
    Generate the autocompletion script for powershell.

    To load completions in your current shell session:

    	localaistack completion powershell | Out-String | Invoke-Expression

    To load completions for every new session, add the output of the above command
    to your powershell profile.
: |-
    以下是用于 PowerShell 的自动补全脚本：

    **在当前 shell 会话中加载自动补全功能：**

    ```powershell
    local aistack completion powershell | Out-String | Invoke-Expression
    ```

    **为了在每个新的 shell 会话中都加载自动补全功能，请将上述命令的输出添加到您的 PowerShell 配置文件（`.ps1` 文件）中：**

    1. 打开您的 PowerShell 配置文件（如果还没有的话）。
    2. 在文件的末尾添加以下内容：

    ```powershell
    $aistack completion powershell | Out-String | Invoke-Expression
    ```

    3. 保存文件并关闭编辑器。
    4. 重新启动 PowerShell，此时新的会话应该已经启用了自动补全功能。
? |
    Generate the autocompletion script for the bash shell.

    This script depends on the 'bash-completion' package.
    If it is not installed already, you can install it via your OS's package manager.

    To load completions in your current shell session:

    	source <(localaistack completion bash)

    To load completions for every new session, execute once:

    #### Linux:

    	localaistack completion bash > /etc/bash_completion.d/localaistack

    #### macOS:

    	localaistack completion bash > $(brew --prefix)/etc/bash_completion.d/localaistack

    You will need to start a new shell for this setup to take effect.
: |-
    以下是用于 Bash shell 的自动补全脚本：

    该脚本依赖于 `bash-completion` 包。如果尚未安装该包，您可以通过操作系统的包管理器进行安装。

    **在当前 shell 会话中加载自动补全功能：**
    ```bash
    source <(localaistack completion bash)
    ```

    **为每个新的 shell 会话加载自动补全功能：**
    只需执行一次以下命令：
    - **对于 Linux：**
      ```bash
      localaistack completion bash > /etc/bash_completion.d/localaistack
      ```
    - **对于 macOS：**
      ```bash
      localaistack completion bash > $(brew --prefix)/etc/bash_completion.d/localaistack
      ```
    **注意：** 需要重新启动一个新的 shell 才能使这些设置生效。
? |
    Generate the autocompletion script for the fish shell.

    To load completions in your current shell session:

    	localaistack completion fish | source

    To load completions for every new session, execute once:

    	localaistack completion fish > ~/.config/fish/completions/localaistack.fish

    You will need to start a new shell for this setup to take effect.
: |-
    以下是用于 Fish Shell 的自动补全脚本：

    **在当前 Shell 会话中加载自动补全功能：**
    ```bash
    local aistack completion fish | source
    ```

    **为每个新会话加载自动补全功能（只需执行一次）：**
    ```bash
    local aistack completion fish > ~/.config/fish/completions/localaistack.fish
    ```

    请注意：要使这些设置生效，你需要重新启动一个新的 Fish Shell 会话。
Generate the autocompletion script for the specified shell: |-
    根据您的要求，以下是一个简单的自动补全脚本，适用于大多数常见的 shell（如 Bash、Zsh 等）：

    ```bash
    #!/bin/bash

    function auto_complete() {
      local completions=()
      local current_word=$1
      local max_words=10

      # 遍历所有可用的补全项
      for word in "${completions[@]}"; do
        # 检查当前单词是否与补全项匹配
        if [ "$current_word" == "$word" ]; then
          # 如果匹配，则将补全项添加到结果列表中
          completions+= "$word"
        fi
      done

      # 如果结果列表的长度大于最大单词数，则只显示前 max_words 个补全项
      if [ ${#completions} -gt $max_words ]; then
        completions=${completions[:$max_words]}
      fi

      # 显示补全项
      echo "Available completions:"
      for word in "${completions[@]}"; do
        echo "$word"
      done
    }

    # 调用自动补全函数
    auto_complete "$current_word"
    ```

    要将此脚本添加到您的 shell 脚本中，请将其保存为一个文件（例如 `auto_complete.sh`），并通过运行 `chmod +x auto_complete.sh` 使其可执行。然后，您可以在需要自动补全功能的命令行中使用 `auto_complete` 函数，如下所示：

    ```bash
    auto_complete "your_command"
    ```

    请注意，这个脚本仅提供了一个基本的自动补全功能。根据您的具体需求，您可能需要对其进行进一步定制和扩展。
? |
    Generate the autocompletion script for the zsh shell.

    If shell completion is not already enabled in your environment you will need
    to enable it.  You can execute the following once:

    	echo "autoload -U compinit; compinit" >> ~/.zshrc

    To load completions in your current shell session:

    	source <(localaistack completion zsh)

    To load completions for every new session, execute once:

    #### Linux:

    	localaistack completion zsh > "${fpath[1]}/_localaistack"

    #### macOS:

    	localaistack completion zsh > $(brew --prefix)/share/zsh/site-functions/_localaistack

    You will need to start a new shell for this setup to take effect.
: |-
    以下是为 Zsh shell 编写的自动补全脚本：

    如果你的环境中尚未启用自动补全功能，你需要先进行启用。你可以执行以下命令一次：

    ```bash
    echo "autoload -U compinit; compinit" >> ~/.zshrc
    ```

    要在当前 shell 会话中加载自动补全功能，执行以下命令：

    ```bash
    source <(localaistack completion zsh)
    ```

    如果要为每个新的 shell 会话都加载自动补全功能，请执行以下命令（根据操作系统不同，路径可能会有所不同）：

    #### Linux:

    ```bash
    localaistack completion zsh > "${fpath[1]}/_localaistack"
    ```

    #### macOS:

    ```bash
    localaistack completion zsh > $(brew --prefix)/share/zsh/site-functions/_localaistack
    ```

    请注意，这些设置需要重启一个新的 shell 会话才能生效。
Generate the autocompletion script for zsh: |-
    以下是一个为 Zsh 编写的自动补全脚本示例：

    ```bash
    #!/bin/bash

    # 定义补全函数
    function complete() {
      local completions=()
      local word=$1

      # 根据不同的命令或上下文，生成不同的补全选项
      case "$word" in
        # 示例 1：生成文件名补全选项
        *.txt
        *.pdf
        *.doc
        *js
        *css
        *jpg
        *png
        *

        # 示例 2：生成命令参数补全选项
        ls
        grep
        cp
        mv
        rm

        # 添加更多的补全选项...

        # 将补全选项添加到 completions 数组中
        completions+=($word)

        # 返回补全选项列表
        return $completions
      esac

      # 使用 completions 函数进行补全
      zsh-completion -c "$completions"
    }

    # 在 Zsh 配置文件中添加自动补全功能
    echo "autoload complete"
    echo "compcomplete *"
    ```

    将上述脚本保存为 `auto-complete.zsh`，然后使用以下命令将其添加到 Zsh 的配置文件中：

    ```bash
    echo "source auto-complete.zsh" >> ~/.zshrc
    ```

    现在，当你输入一个单词并按回车键时，Zsh 将会使用 `complete` 函数来提供自动补全建议。你可以根据需要修改脚本中的补全选项，以适应你的具体需求。
Get service status: 获取服务状态
? "HEAD 现在位于 2dc3ce21 Remove pipeline cache mutexes (#19195)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  2dc3ce21\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=none’; did you mean ‘-maddress-mode=long’?\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 2dc3ce21：删除流水线缓存互斥锁（#19195）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache——建议安装它以加快编译速度；或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 处理器  \n-- 正在添加 CPU 后端版本 ggml-cpu（配置选项：-march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构：CMAKE_CUDA_ARCHITECTURES=70，CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 版本：0.9.5  \n-- ggml 的提交版本：2dc3ce21  \n-- 找到了 OpenSSL（版本：3.0.2）  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存至：/usr/local/llama.cpp/build  \n\n正在整合目标 ggml-base 生成的编译器依赖项……  \n[ 2%] 目标 ggml-base 已构建完成  \n[ 2%] 正在构建 CUDA 对象文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n错误信息：  \ngcc-11: 未识别的命令行选项 “-compress-mode=none”；您是否想使用 “-maddress-mode=long”？  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：出现错误  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：出现错误  \ngmake: *** [Makefile:146]：出现错误"
? "HEAD 现在位于 2dc3ce21 Remove pipeline cache mutexes (#19195)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  2dc3ce21-dirty\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n[  0%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n[  2%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n[  2%] Linking CXX shared library ../../bin/libggml-base.so\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\n/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n  435 |         function(_Functor&& __f)\n      |                                                                                                                                                 ^ \n/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n  530 |         operator=(_Functor&& __f)\n      |                                                                                                                                                  ^ \n/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 2dc3ce21：正在删除流水线缓存互斥锁（#19195）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache——可以考虑安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端模块  \n-- 检测到 x86 架构  \n-- 正在添加 CPU 后端变体 ggml-cpu（配置选项：-march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构：CMAKE_CUDA_ARCHITECTURES=70，CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本：GNU 11.4.0  \n-- 正在包含 CUDA 后端模块  \n-- ggml 的版本：0.9.5  \n-- ggml 的提交版本：2dc3ce21-dirty  \n-- 找到了 OpenSSL（版本：3.0.2）  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存到：/usr/local/llama.cpp/build  \n\n正在整合目标 ggml-base 生成的编译器依赖项：  \n[ 0%] 构建 C 对象文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o  \n[ 0%] 构建 CXX 对象文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o  \n[ 1%] 构建 C 对象文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o  \n[ 1%] 构建 CXX 对象文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o  \n[ 1%] 构建 CXX 对象文件 ggml/src/CMakeFiles/ggml-opt.cpp.o  \n[ 1%] 构建 CXX 对象文件 ggml/src/CMakeFiles/ggml-threading.cpp.o  \n[ 1%] 构建 C 对象文件 ggml/src/CMakeFiles/ggml-quants.c.o  \n[ 2%] 构建 CXX 对象文件 ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o  \n[ 2%] 链接 CXX 共享库：../../bin/libggml-base.so  \n[ 2%] 目标 ggml-base 已构建完成  \n\n在构建过程中出现错误：  \n/usr/include/c++/11/bits/std_function.h:435:145: 错误：参数包未使用 “...” 进行展开  \n同样，在 /usr/include/c++/11/bits/std_function.h:530 也出现了类似的错误。  \n错误信息提示需要使用 “_ArgTypes” 来正确展开参数包。  \n\n错误日志：  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：错误 1  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：错误 2  \ngmake: *** [Makefile:146]：错误 2"
? "HEAD 现在位于 2dc3ce21 Remove pipeline cache mutexes (#19195)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  2dc3ce21-dirty\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  2%] Built target ggml-base\nConsolidate compiler generated dependencies of target ggml-cuda\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\n/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n  435 |         function(_Functor&& __f)\n      |                                                                                                                                                 ^ \n/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n  530 |         operator=(_Functor&& __f)\n      |                                                                                                                                                  ^ \n/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 2dc3ce21：删除流水线缓存互斥锁（#19195）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache——建议安装它以加快编译速度；或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 架构  \n-- 正在添加 CPU 后端版本 ggml-cpu（配置选项：-march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构：CMAKE_CUDA_ARCHITECTURES=70，CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 的版本：0.9.5  \n-- ggml 的提交版本：2dc3ce21-dirty  \n-- 找到了 OpenSSL（版本：3.0.2）  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存至：/usr/local/llama.cpp/build  \n\n正在整合目标 ggml-base 由编译器生成的依赖关系……  \n[ 2%] 目标 ggml-base 已构建完成  \n\n正在整合目标 ggml-cuda 由编译器生成的依赖关系……  \n[ 2%] 正在构建 CUDA 对象文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n错误信息：  \n文件 `/usr/include/c++/11/bits/std_function.h` 的第 435 行和第 530 行存在问题：参数包未能正确展开。  \n具体错误内容如下：  \n```\n435 |         function(_Functor&& __f)\n      |                                                                                                                                                 ^\n530 |         operator=(_Functor&& __f)\n      |                                                                                                                                                  ^\n```\n\n错误代码：`gmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]`  \n错误代码：`gmake[1]: *** [CMakeFiles/Makefile2:1867]`  \n错误代码：`gmake: *** [Makefile:146]`  \n\n请检查相关源代码文件（`/usr/include/c++/11/bits/std_function.h`），并修复导致参数包无法正确展开的问题。"
? "HEAD 现在位于 3bc8d2cf Bump cmake max version (needed for Windows on Snapdragon builds) (#19188)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- The CUDA compiler identification is NVIDIA 11.5.119\n-- Detecting CUDA compiler ABI info\n-- Detecting CUDA compiler ABI info - done\n-- Check for working CUDA compiler: /usr/bin/nvcc - skipped\n-- Detecting CUDA compile features\n-- Detecting CUDA compile features - done\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  3bc8d2cf\n-- Found OpenSSL: /usr/lib/x86_64-linux-gnu/libcrypto.so (found version \"3.0.2\")  \n-- Performing Test OPENSSL_VERSION_SUPPORTED\n-- Performing Test OPENSSL_VERSION_SUPPORTED - Success\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\n[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n[  0%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n[  2%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n[  2%] Linking CXX shared library ../../bin/libggml-base.so\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=size’\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 3bc8d2cf 版本，用于更新 CMake 的最大版本（这对于在 Snapdragon 平台上构建 Windows 应用程序是必需的）（#19188）  \nCMAKE_BUILD_TYPE=Release  \n\n-- 警告：未找到 ccache——可以考虑安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 处理器  \n-- 正在添加 CPU 后端变体 ggml-cpu（配置选项：-march=native）  \n-- 找到了 CUDA 工具包  \n-- CUDA 编译器的版本是 NVIDIA 11.5.119  \n-- 正在检测 CUDA 编译器的 ABI 信息  \n-- 检测 CUDA 编译器的 ABI 信息已完成  \n-- 检查 CUDA 编译器是否可用：/usr/bin/nvcc（跳过此步骤）  \n-- 正在检测 CUDA 的编译特性  \n-- 检测 CUDA 的编译特性已完成  \n-- 使用的配置选项：CMAKE_CUDA_ARCHITECTURES=70, CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器的版本是 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 的版本是 0.9.5  \n-- ggml 的提交版本是 3bc8d2cf  \n-- 找到了 OpenSSL：/usr/lib/x86_64-linux-gnu/libcrypto.so（版本为 3.0.2）  \n-- 正在执行 OPENSSL_VERSION_SUPPORTED 测试  \n-- OPENSSL_VERSION_SUPPORTED 测试成功  \n-- 找到的 OpenSSL 版本是 3.0.2  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存到：/usr/local/llama.cpp/build  \n\n[ 0%] 正在构建 C 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o  \n[ 0%] 正在构建 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o  \n[ 1%] 正在构建 C 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o  \n[ 1%] 正在构建 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o  \n[ 1%] 正在构建 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o  \n[ 1%] 正在构建 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o  \n[ 1%] 正在构建 C 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o  \n[ 2%] 正在构建 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o  \n[ 2%] 正在链接 C++ 共享库 ../../bin/libggml-base.so  \n[ 2%] 目标 ggml-base 已构建完成  \n[ 2%] 正在构建与 CUDA 相关的源文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n**错误信息：**  \ngcc-11: 未识别命令行选项 “-compress-mode=size”  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：出现错误 1  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：出现错误 2  \ngmake: *** [Makefile:146]：出现错误 2"
? "HEAD 现在位于 3bc8d2cf Bump cmake max version (needed for Windows on Snapdragon builds) (#19188)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  3bc8d2cf\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=none’; did you mean ‘-maddress-mode=long’?\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 3bc8d2cf 版本，用于更新 CMake 的最大版本（这对于在 Snapdragon 平台上构建 Windows 系统的应用程序是必需的）（#19188）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache 工具——可以考虑安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 处理器  \n-- 正在添加 CPU 后端变体 ggml-cpu（配置为 -march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构为 CMAKE_CUDA_ARCHITECTURES=70 和 CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 的版本为 0.9.5  \n-- ggml 的提交版本为 3bc8d2cf  \n-- 找到了 OpenSSL，版本为 3.0.2  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存到：/usr/local/llama.cpp/build  \n\n现在正在整合目标 ggml-base 生成的编译器依赖项：  \n[ 2%] 目标 ggml-base 已构建完成  \n[ 2%] 正在构建 CUDA 对象文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n错误信息：  \ngcc-11: 未识别的命令行选项 “-compress-mode=none”；您是否想使用 “-maddress-mode=long”？  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：出现错误  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：出现错误  \ngmake: *** [Makefile:146]：出现错误"
? "HEAD 现在位于 3bc8d2cf Bump cmake max version (needed for Windows on Snapdragon builds) (#19188)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  3bc8d2cf\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=size’\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 3bc8d2cf 版本，用于更新 CMake 的最大版本（这对于在 Snapdragon 平台上构建 Windows 应用程序是必需的）（#19188）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache——可以考虑安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 处理器  \n-- 正在添加 CPU 后端变体 ggml-cpu（配置选项：-march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构：CMAKE_CUDA_ARCHITECTURES=70，CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 的版本为 0.9.5  \n-- ggml 的提交版本为 3bc8d2cf  \n-- 找到了 OpenSSL（版本：3.0.2）  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n-- 构建文件已保存到：/usr/local/llama.cpp/build  \n\n正在整合目标 ggml-base 由编译器生成的依赖关系……  \n[ 2%] 目标 ggml-base 已构建完成  \n[ 2%] 正在构建 CUDA 对象文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n错误信息：  \ngcc-11: 未识别的命令行选项 “-compress-mode=size”  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：出现错误  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：出现错误  \ngmake: *** [Makefile:146]：出现错误"
? "HEAD 现在位于 3bc8d2cf Bump cmake max version (needed for Windows on Snapdragon builds) (#19188)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  3bc8d2cf\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\nCMake Warning:\n  Manually-specified variables were not used by the project:\n\n    CUDA_TOOLKIT_ROOT_DIR\n\n\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=size’\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "HEAD 现在位于 3bc8d2cf 版本，用于更新 CMake 的最大版本（这对于在 Snapdragon 平台上构建 Windows 应用程序是必需的）（#19188）  \nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache——可以考虑安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端支持  \n-- 检测到 x86 处理器  \n-- 正在添加 CPU 后端变体 ggml-cpu（配置为 -march=native）  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构：CMAKE_CUDA_ARCHITECTURES=70，CMAKE_CUDA_ARCHITECTURES_NATIVE=  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端支持  \n-- ggml 的版本为 0.9.5  \n-- ggml 的提交版本为 3bc8d2cf  \n-- 找到了 OpenSSL（版本为 3.0.2）  \n-- 正在为目标 “common” 生成嵌入式许可证文件  \n-- 配置已完成  \n-- 生成过程已完成  \n\nCMake 警告：  \n项目中未使用手动指定的变量：`CUDA_TOOLKIT_ROOT_DIR`  \n\n-- 构建文件已生成到：/usr/local/llama.cpp/build  \n\n正在整合目标 ggml-base 生成的编译依赖项：  \n[ 2%] 目标 ggml-base 已构建完成  \n[ 2%] 正在构建 CUDA 对象文件 ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o  \n\n错误信息：  \ngcc-11: 未识别的命令行选项 ‘-compress-mode=size’  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：错误 1  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：错误 2  \ngmake: *** [Makefile:146]：错误 2"
Help about any command: 关于任何命令的帮助信息
? |-
    Help provides help for any command in the application.
    Simply type localaistack help [path to command] for full details.
: "“Help”功能可以为应用程序中的任何命令提供帮助。  \n只需输入 `localaistack help [命令路径]` 即可获取详细信息。"
Host to bind llama.cpp server: 用于绑定 llama.cpp 服务器的主机
Initialize LocalAIStack interactive configuration: 初始化 LocalAIStack 的交互式配置
Install a module: 安装一个模块。
Installed: 已安装
'Installing module: %s': 正在安装模块：%s
List all available modules: 列出所有可用的模块。
List available LLM providers: 以下是可用的大型语言模型（LLM）提供商列表：
List downloaded models: 已下载的模型列表
LocalAIStack - Local AI workstation management: LocalAIStack – 本地人工智能工作站管理系统
? LocalAIStack is an open, modular software stack for building and operating local AI workstations. It provides unified control over AI development environments, inference runtimes, models, and applications.
: LocalAIStack 是一个开源的、模块化的软件栈，用于构建和运行本地人工智能工作站。它提供了对人工智能开发环境、推理运行时、模型以及应用程序的统一管理功能。
Manage AI models: 管理人工智能模型
Manage LLM providers: 管理大型语言模型（LLM）提供商
Manage services: 管理服务
Manage software modules: 管理软件模块
'Manageable modules:': 可管理的模块：
Maximum number of results per source: 每个来源的最大结果数量
Module %s installed successfully.: 模块 %s 安装成功。
Module %s uninstalled successfully.: 模块 %s 已成功卸载。
'Module install failed: %s': 模块安装失败：%s
Not installed: 未安装
Port to bind llama.cpp server: 用于绑定 llama.cpp 服务器的端口
Preferred interaction language: 首选的交互语言
Remove a downloaded model: 删除已下载的模型。
Run a local model: 运行一个本地模型。
Search for models: 搜索模型
Show system information: 显示系统信息
SiliconFlow API key: SiliconFlow API密钥
Source of the model (ollama, huggingface, modelscope): 模型的来源（ollama、huggingface、modelscope）
Source to download from (ollama, huggingface, modelscope): 可以从以下来源下载模型：ollama、huggingface、modelscope。
Source to search (ollama, huggingface, modelscope, or all): 要搜索的来源（ollama、huggingface、modelscope 或全部）：
Specific GGUF filename to run: 要运行的具体 GGUF 文件名
Specific model file to download (e.g. Q4_K_M.gguf): 需要下载的具体模型文件（例如：Q4_K_M.gguf）
Start a service: 启动一个服务
Stop a service: 停止一个服务
System management: 系统管理
Tensor split for multi-GPU (comma-separated percentages): 用于多 GPU 的张量分割（百分比值以逗号分隔）
Translation API base URL: 翻译 API 的基础 URL
Translation model: 翻译模型
Translation provider: 翻译服务提供商
Translation timeout in seconds: 翻译超时时间（以秒为单位）
Uninstall a module: 卸载一个模块
'Uninstalling module: %s': 正在卸载模块：%s
config file (default is $HOME/.localaistack/config.yaml): 配置文件（默认路径为 $HOME/.localaistack/config.yaml）
config file path (default is ~/.localaistack/config.yaml): 配置文件路径（默认为 ~/.localaistack/config.yaml）
disable completion descriptions: 禁用补全描述
? 'fatal: 无法访问 ''https://github.com/ggerganov/llama.cpp.git/''：gnutls_handshake() failed: The TLS connection was non-properly terminated.'
: 错误：无法访问 ‘https://github.com/ggerganov/llama.cpp.git/’：gnutls_handshake() 失败：TLS 连接终止方式不正确。
help for download: 关于下载的帮助信息
help for install: 安装帮助
help for list: 关于列表的帮助信息：
help for rm: "关于 `rm` 命令的帮助信息：  \n`rm` 是一个用于删除文件的命令。它接受一个或多个文件名作为参数，并将这些文件从文件系统中删除。  \n\n**基本用法：**  \n```bash\nrm 文件名1 文件名2 文件名3\n```\n\n**注意：**  \n- 删除的文件将无法恢复。  \n- 如果文件被其他程序占用（例如，文件正在被读取或写入），`rm` 命令可能会失败并给出错误信息。  \n- 如果文件位于目录中，`rm` 也会删除该目录及其所有内容。  \n\n**示例：**  \n- 删除名为 `example.txt` 的文件：  \n  ```bash\n  rm example.txt\n  ```  \n- 删除名为 `my_directory` 的目录及其所有内容：  \n  ```bash\n  rm my_directory\n  ```  \n\n**更多选项：**  \n- `-f` 或 `--force`：强制删除文件，即使文件被其他程序占用。  \n- `-i` 或 `--ignore-exists`：在删除文件之前显示提示信息。  \n- `-r` 或 `--recursive`：递归删除目录及其所有内容。  \n\n**示例（使用 `-r` 选项）：**  \n- 删除名为 `my_directory` 的目录及其所有内容：  \n  ```bash\n  rm -r my_directory\n  ```"
help for run: 关于如何运行的帮助
help for search: 搜索帮助
help for uninstall: 关于卸载的帮助
'install step %s failed: %w': 安装步骤 %s 失败：%w
'module %q check failed: %s': 模块 %q 的检查失败：%s
'module %q check failed: %v': 模块 %q 的检查失败：%v
verbose output: 详细输出（verbose output）
? |-
    命中:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease
    命中:5 https://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease
    命中:6 https://download.docker.com/linux/ubuntu jammy InRelease
    命中:2 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease
    命中:3 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease
    命中:4 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease
    命中:7 http://security.ubuntu.com/ubuntu jammy-security InRelease
    获取:8 https://pkgs.tailscale.com/stable/ubuntu jammy InRelease
    已下载 6,581 B，耗时 1秒 (5,222 B/s)
    正在读取软件包列表...
    正在读取软件包列表...
    正在分析软件包的依赖关系树...
    正在读取状态信息...
    ca-certificates 已经是最新版 (20240203~22.04.1)。
    curl 已经是最新版 (7.81.0-1ubuntu1.21)。
    python3 已经是最新版 (3.10.6-1~22.04.1)。
    tar 已经是最新版 (1.34+dfsg-1ubuntu0.1.22.04.2)。
    tar 已设置为手动安装。
    您也许需要运行“apt --fix-broken install”来修正上面的错误。
    下列软件包有未满足的依赖关系：
     clash-verge : 依赖: libwebkit2gtk-4.1-0 但是它将不会被安装
    E: 有未能满足的依赖关系。请尝试不指明软件包的名字来运行“apt --fix-broken install”(也可以指定一个解决办法)。
: |-
    匹配到的软件源地址：
    1. https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64 (InRelease)
    5. https://apt.postgresql.org/pub/repos/apt/jammy-pgdg (InRelease)
    6. https://download.docker.com/linux/ubuntu/jammy (InRelease)
    2. http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy (InRelease)
    3. http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates (InRelease)
    4. http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports (InRelease)
    7. https://security.ubuntu.com/ubuntu/jammy-security (InRelease)
    8. https://pkgs.tailscale.com/stable/ubuntu/jammy (InRelease)

    已下载的数据量为：6,581 字节，耗时 1 秒（下载速度为 5,222 字节/秒）。

    当前正在读取软件包列表……
    同时正在分析这些软件包之间的依赖关系……
    此外，以下软件包的依赖关系尚未得到满足：
    - `clash-verge` 依赖于 `libwebkit2gtk-4.1-0`，但该依赖关系无法被满足（因此 `clash-verge` 无法被安装）。

    提示：您可能需要运行 `apt --fix-broken install` 命令来修复这些依赖关系问题。您也可以尝试在运行该命令时指定具体的解决方案。
? "来自 https://github.com/ggerganov/llama.cpp\n   3bc8d2cf..2dc3ce21  master     -> origin/master\n * [新标签]            b7903      -> b7903\nHEAD 现在位于 2dc3ce21 Remove pipeline cache mutexes (#19195)\nCMAKE_BUILD_TYPE=Release\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- CUDA Toolkit found\n-- Using CMAKE_CUDA_ARCHITECTURES=70 CMAKE_CUDA_ARCHITECTURES_NATIVE=\n-- CUDA host compiler is GNU 11.4.0\n-- Including CUDA backend\n-- ggml version: 0.9.5\n-- ggml commit:  2dc3ce21\n-- OpenSSL found: 3.0.2\n-- Generating embedded license file for target: common\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/llama.cpp/build\nConsolidate compiler generated dependencies of target ggml-base\n[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n[  0%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n[  2%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n[  2%] Linking CXX shared library ../../bin/libggml-base.so\n[  2%] Built target ggml-base\n[  2%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\ngcc-11: error: unrecognized command-line option ‘-compress-mode=none’; did you mean ‘-maddress-mode=long’?\ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o] 错误 1\ngmake[1]: *** [CMakeFiles/Makefile2:1867：ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/all] 错误 2\ngmake: *** [Makefile:146：all] 错误 2"
: "来自：https://github.com/ggerganov/llama.cpp  \n版本更新：3bc8d2cf..2dc3ce21（从 master 分支更新到 origin/master）  \n* 新标签：b7903  \n\n当前 HEAD 指向的版本为 2dc3ce21；此版本中包含了一个用于移除流水线缓存互斥锁的修复（修复编号：#19195）。  \n\n配置选项如下：  \n```\nCMAKE_BUILD_TYPE=Release  \n-- 警告：未找到 ccache 工具——建议安装它以加快编译速度；或者可以通过设置 GGML_CCACHE=OFF 来禁用此警告  \n-- CMAKE_SYSTEM_PROCESSOR: x86_64  \n-- GGML_SYSTEM_ARCH: x86  \n-- 正在包含 CPU 后端模块  \n-- 检测到 x86 架构  \n-- 正在添加 CPU 后端变体（ggml-cpu），并设置编译选项为 -march=native  \n-- 找到了 CUDA 工具包  \n-- 使用的 CUDA 架构版本为 70（CMAKE_CUDA_ARCHITECTURES=70），同时支持原生架构（CMAKE_CUDA_ARCHITECTURES_NATIVE=1）  \n-- CUDA 主机编译器版本为 GNU 11.4.0  \n-- 正在包含 CUDA 后端模块  \n-- ggml 的版本为 0.9.5  \n-- ggml 的提交版本为 2dc3ce21  \n-- 找到了 OpenSSL 库（版本：3.0.2）  \n-- 为 “common” 目标生成了嵌入式许可证文件  \n-- 配置工作已完成  \n-- 生成工作已完成  \n-- 编译文件已保存到：/usr/local/llama.cpp/build  \n\n接下来，将整合目标 “ggml-base” 生成的编译依赖项：  \n[ 0%] 编译 C 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o  \n[ 0%] 编译 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o  \n[ 1%] 编译 C 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o  \n[ 1%] 编译 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o  \n[ 1%] 编译 C++ 语言源文件 ggml/src/CMakeFiles/ggml-opt.cpp.o  \n[ 1%] 编译 C++ 语言源文件 ggml/src/CMakeFiles/ggml-threading.cpp.o  \n[ 1%] 编译 C 语言源文件 ggml/src/CMakeFiles/ggml-quants.c.o  \n[ 2%] 编译 C++ 语言源文件 ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o  \n[ 2%] 链接 C++ 共享库 ../../bin/libggml-base.so  \n[ 2%] 目标 “ggml-base” 已编译完成  \n\n但在编译过程中出现了错误：  \n```\ngcc-11: 未识别的命令行选项 ‘-compress-mode=none’；您是否想使用 ‘-maddress-mode=long’？  \ngmake[2]: *** [ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make:76]：错误 1  \ngmake[1]: *** [CMakeFiles/Makefile2:1867]：错误 2  \ngmake: *** [Makefile:146]：错误 2  \n```"
? "正克隆到 '/usr/local/llama.cpp'...\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\nCMAKE_BUILD_TYPE=Release\n-- Found Git: /usr/bin/git (found version \"2.34.1\") \n-- The ASM compiler identification is GNU\n-- Found assembler: /usr/bin/cc\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n-- Found Threads: TRUE  \n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- GGML_SYSTEM_ARCH: x86\n-- Including CPU backend\n-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n-- Found OpenMP: TRUE (found version \"4.5\")  \n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- Found CUDAToolkit: /usr/local/cuda/include (found version \"12.9.86\") \n-- CUDA Toolkit found\nCMake Error at /usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:726 (message):\n  Compiling the CUDA compiler identification source file\n  \"CMakeCUDACompilerId.cu\" failed.\n\n  Compiler: CMAKE_CUDA_COMPILER-NOTFOUND\n\n  Build flags:\n\n  Id flags: -v\n\n  \n\n  The output was:\n\n  No such file or directory\n\n  \n\n  \n\nCall Stack (most recent call first):\n  /usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:6 (CMAKE_DETERMINE_COMPILER_ID_BUILD)\n  /usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:48 (__determine_compiler_id_test)\n  /usr/share/cmake-3.22/Modules/CMakeDetermineCUDACompiler.cmake:298 (CMAKE_DETERMINE_COMPILER_ID)\n  ggml/src/ggml-cuda/CMakeLists.txt:58 (enable_language)\n\n\n-- Configuring incomplete, errors occurred!\nSee also \"/usr/local/llama.cpp/build/CMakeFiles/CMakeOutput.log\".\nSee also \"/usr/local/llama.cpp/build/CMakeFiles/CMakeError.log\"."
: |-
    正在将文件克隆到 `/usr/local/llama.cpp`...

    -- C 编译器的版本是 GNU 11.4.0
    -- CXX 编译器的版本也是 GNU 11.4.0
    -- 正在检测 C 编译器的 ABI 信息
    -- 检测 C 编译器的 ABI 信息已完成
    -- 检查 C 编译器是否可用：/usr/bin/cc（已跳过）
    -- 正在检测 C 编译器的特性
    -- 检测 C 编译器的特性已完成
    -- 正在检测 CXX 编译器的 ABI 信息
    -- 检测 CXX 编译器的 ABI 信息已完成
    -- 检查 CXX 编译器是否可用：/usr/bin/c++（已跳过）
    -- 正在检测 CXX 编译器的特性
    -- 检测 CXX 编译器的特性已完成

    CMAKE_BUILD_TYPE=Release

    -- 找到了 Git：/usr/bin/git（版本为 2.34.1）
    -- ASM 编译器的版本是 GNU
    -- 找到了汇编器：/usr/bin/cc
    -- 正在查找 pthread.h 文件
    -- 查找 pthread.h 文件成功
    -- 正在执行测试 CMAKEHAVE_LIBC_PTHREAD
    -- 测试成功

    -- 检查是否支持多线程：结果为 TRUE

    -- 警告：未找到 ccache 工具。建议安装它以加快编译速度，或者通过设置 GGML_CCACHE=OFF 来忽略此警告。
    -- CMAKE_SYSTEM_PROCESSOR 的类型是 x86_64
    -- GGML_SYSTEM_ARCH 的类型是 x86
    -- 正在启用 CPU 后端支持
    -- 找到了 OpenMP_C（版本为 4.5）
    -- 找到了 OpenMP_CXX（版本为 4.5）
    -- OpenMP 的版本为 4.5

    -- 检测到 x86 架构，因此添加了相应的 CPU 后端配置（ggml-cpu，设置 -march=native）

    -- 找到了 CUDA Toolkit：/usr/local/cuda/include（版本为 12.9.86）

    **CMake 错误：**
    在 `/usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake` 文件的第 726 行发生错误：
    尝试编译用于确定 CUDA 编译器版本的源文件 “CMakeCUDACompilerId.cu” 时失败。
    错误信息：`CMAKE_CUDACompiler-NOTFOUND`

    **构建选项：**
    - 显示编译器版本信息：`-v`

    **错误输出：**
    “找不到相应的文件或目录。”

    **调用栈（最近的一次调用在最前面）：**
    - `/usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:6`（CMAKE_DETERMINECompiler_ID_BUILD）
    - `/usr/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:48`（__determineCompiler_id_test）
    - `/usr/share/cmake-3.22/Modules/CMakeDetermineCUDACompiler.cmake:298`（CMAKE_DETERMINECompiler_ID）
    - `ggml/src/ggml-cuda/CMakeLists.txt:58`（enable_language）

    **注意：**
    配置过程因错误而未完成。请查看 `/usr/local/llama.cpp/build/CMakeFiles/CMakeOutput.log` 和 `/usr/local/llama.cpp/build/CMakeError.log` 文件以获取更多详细信息。
? |-
    获取:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]
    获取:3 https://download.docker.com/linux/ubuntu jammy InRelease [48.5 kB]
    获取:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,328 kB]
    命中:2 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease
    获取:7 https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages [68.5 kB]
    获取:4 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease [128 kB]
    获取:6 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease [127 kB]
    获取:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]
    获取:9 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main i386 Packages [939 kB]
    获取:10 https://pkgs.tailscale.com/stable/ubuntu jammy InRelease
    获取:11 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 Packages [3,188 kB]
    获取:12 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main Translation-en [488 kB]
    获取:13 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 DEP-11 Metadata [112 kB]
    获取:14 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 c-n-f Metadata [19.1 kB]
    获取:15 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 Packages [5,168 kB]
    获取:16 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted Translation-en [972 kB]
    获取:17 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 DEP-11 Metadata [212 B]
    获取:18 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 Packages [1,250 kB]
    获取:19 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe i386 Packages [792 kB]
    获取:20 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe Translation-en [311 kB]
    获取:21 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 DEP-11 Metadata [359 kB]
    获取:22 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 c-n-f Metadata [30.2 kB]
    获取:23 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/multiverse amd64 DEP-11 Metadata [940 B]
    获取:24 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/main amd64 DEP-11 Metadata [7,288 B]
    获取:25 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/restricted amd64 DEP-11 Metadata [212 B]
    获取:26 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/universe amd64 DEP-11 Metadata [10.2 kB]
    获取:27 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/multiverse amd64 DEP-11 Metadata [212 B]
    获取:28 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,905 kB]
    获取:29 https://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease [107 kB]
    获取:30 https://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 Packages [401 kB]
    获取:31 http://security.ubuntu.com/ubuntu jammy-security/main i386 Packages [753 kB]
    获取:32 http://security.ubuntu.com/ubuntu jammy-security/main amd64 DEP-11 Metadata [54.6 kB]
    获取:33 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 DEP-11 Metadata [208 B]
    获取:34 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,012 kB]
    获取:35 http://security.ubuntu.com/ubuntu jammy-security/universe i386 Packages [681 kB]
    获取:36 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 DEP-11 Metadata [125 kB]
    获取:37 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 c-n-f Metadata [22.5 kB]
    获取:38 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 DEP-11 Metadata [208 B]
    已下载 22.5 MB，耗时 4秒 (5,371 kB/s)
    正在读取软件包列表...
    正在读取软件包列表...
    正在分析软件包的依赖关系树...
    正在读取状态信息...
    ca-certificates 已经是最新版 (20240203~22.04.1)。
    curl 已经是最新版 (7.81.0-1ubuntu1.21)。
    python3 已经是最新版 (3.10.6-1~22.04.1)。
    tar 已经是最新版 (1.34+dfsg-1ubuntu0.1.22.04.2)。
    tar 已设置为手动安装。
    您也许需要运行“apt --fix-broken install”来修正上面的错误。
    下列软件包有未满足的依赖关系：
     clash-verge : 依赖: libwebkit2gtk-4.1-0 但是它将不会被安装
    E: 有未能满足的依赖关系。请尝试不指明软件包的名字来运行“apt --fix-broken install”(也可以指定一个解决办法)。
: |-
    获取的软件包列表如下：

    - https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/InRelease [1,581 B]
    - https://download.docker.com/linux/ubuntu/jammy/InRelease [48.5 kB]
    - https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/Packages [2,328 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy/InRelease
    - https://download.docker.com/linux/ubuntu/jammy/stable/amd64/Packages [68.5 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/InRelease [128 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports/InRelease [127 kB]
    - https://security.ubuntu.com/ubuntu/jammy-security/InRelease [129 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/main/i386/Packages [939 kB]
    - https://pkgs.tailscale.com/stable/ubuntu/jammy/InRelease
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/main/amd64/Packages [3,188 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/main/Translation-en [488 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/main/amd64/DEP-11 Metadata [112 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/main/amd64/c-n-f Metadata [19.1 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/restricted/amd64/Packages [5,168 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/restricted/Translation-en [972 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/restricted/DEP-11 Metadata [212 B]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/universe/amd64/Packages [1,250 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/universe/i386/Packages [792 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/universe/Translation-en [311 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/universe/amd64/DEP-11 Metadata [359 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/universe/amd64/c-n-f Metadata [30.2 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-updates/multiverse/amd64/DEP-11 Metadata [940 B]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports/main/amd64/DEP-11 Metadata [7,288 B]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports/restricted/amd64/DEP-11 Metadata [212 B]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports/universe/amd64/DEP-11 Metadata [10.2 kB]
    - http://mirrors.tuna.tsinghua.edu.cn/ubuntu/jammy-backports/multiverse/amd64/DEP-11 Metadata [212 B]
    - http://security.ubuntu.com/ubuntu/jammy-security/main/amd64/Packages [2,905 kB]
    - https://apt.postgresql.org/pub/repos/apt/jammy-pgdg/InRelease [107 kB]
    - https://apt.postgresql.org/pub/repos/apt/jammy-pgdg/main/amd64/Packages [401 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/main/i386/Packages [753 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/main/amd64/DEP-11 Metadata [54.6 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/restricted/amd64/DEP-11 Metadata [208 B]
    - http://security.ubuntu.com/ubuntu/jammy-security/universe/amd64/Packages [1,012 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/universe/i386/Packages [681 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/universe/amd64/DEP-11 Metadata [125 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/universe/amd64/c-n-f Metadata [22.5 kB]
    - http://security.ubuntu.com/ubuntu/jammy-security/multiverse/amd64/DEP-11 Metadata [208 B]

    已下载的总大小为 22.5 MB，耗时 4 秒（平均下载速度为 5,371 kB/s）。

    当前正在读取软件包列表、分析软件包的依赖关系树以及状态信息。

    注意：`ca-certificates`、`curl`、`python3` 和 `tar` 都已更新到最新版本。您可能需要运行 `apt --fix-broken install` 命令来修复某些可能存在的安装问题。

    此外，以下软件包存在未满足的依赖关系：
    - `clash-verge` 依赖于 `libwebkit2gtk-4.1-0`，但由于某些原因，该依赖关系无法被满足，因此 `clash-verge` 无法被安装。

    提示：您可以尝试不指定软件包的名称来运行 `apt --fix-broken install` 命令，或者尝试找到并解决这些依赖关系问题。
详细输出（verbose output）: 详细输出（verbose output）：
详细输出（verbose output）：: 详细输出（verbose output）：
配置文件（默认路径为 $HOME/.localaistack/config.yaml）: 配置文件（默认路径为 $HOME/.localaistack/config.yaml）
